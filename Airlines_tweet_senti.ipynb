{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create Dataframe & clean Tweets\n",
    "\n",
    "#Labeled Data\n",
    "df = pd.read_csv('Tweets.csv')\n",
    "df = df[[u'airline_sentiment',u'text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[:,'text'] = df.loc[:,'text'].map(tweet_cleaner)\n",
    "\n",
    "#unlabled Data\n",
    "udf = pd.read_csv('Tweets_Unlabeled1.csv')\n",
    "udf = udf[[u'text']]\n",
    "udf.loc[:,'text'] = udf.loc[:,'text'].map(tweet_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus you ve added commercials to the experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i didn t today must mean i need to take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>it s really aggressive to blast obnoxious ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                                          what said\n",
       "1          positive  plus you ve added commercials to the experienc...\n",
       "2           neutral  i didn t today must mean i need to take anothe...\n",
       "3          negative  it s really aggressive to blast obnoxious ente...\n",
       "4          negative           and it s a really big bad thing about it"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Categorical text values of sentiment to integer categorical values \n",
    "def integer_converter(text):\n",
    "    if str.lower(text) ==\"neutral\":\n",
    "        return 2\n",
    "    elif str.lower(text) ==\"positive\":\n",
    "        return 4\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "df.loc[:,'airline_sentiment'] = df.loc[:,'airline_sentiment'] .map(integer_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>what said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>plus you ve added commercials to the experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>i didn t today must mean i need to take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>it s really aggressive to blast obnoxious ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment                                               text\n",
       "0                  2                                          what said\n",
       "1                  4  plus you ve added commercials to the experienc...\n",
       "2                  2  i didn t today must mean i need to take anothe...\n",
       "3                  0  it s really aggressive to blast obnoxious ente...\n",
       "4                  0           and it s a really big bad thing about it"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58812</td>\n",
       "      <td>Arrive flyLAXairport to find precheck closed a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58813</td>\n",
       "      <td>AA438 AmericanAir tells CBSDFW the flight retu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58814</td>\n",
       "      <td>AmericanAir gate representatives in Dallas who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58815</td>\n",
       "      <td>Seattle travelers will feel safe in hotels ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58816</td>\n",
       "      <td>FlyFrontier sorry for being mean the other day...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "58812  Arrive flyLAXairport to find precheck closed a...\n",
       "58813  AA438 AmericanAir tells CBSDFW the flight retu...\n",
       "58814  AmericanAir gate representatives in Dallas who...\n",
       "58815  Seattle travelers will feel safe in hotels ton...\n",
       "58816  FlyFrontier sorry for being mean the other day..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.text\n",
    "y = df.airline_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "def labelize_tweets_ug(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledSentence(words=['hey', 'think', 'someone', 'could', 'meet', 'me', 'with', 'my', 'book', 'when', 'i', 'arrive', 'at', 'at', 'it', 's', 'yes', 'please', 'amypoehler', 'oscar', 'took', 'it'], tags=['all_3620'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x_w2v[10]\n",
    "#this what labelize tweet looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 265912.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#build vocab\n",
    "model_ug_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=4, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dbow.build_vocab([x for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14640/14640 [00:00<00:00, 702714.64it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 843388.83it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 867750.24it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 952112.80it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 843296.17it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1056805.22it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 867676.67it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1834013.64it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 867971.03it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1017879.70it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1054500.36it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1553524.53it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 483862.82it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 440489.02it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1225592.00it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 922572.95it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1476107.85it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 950800.70it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 980058.90it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 491107.23it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 865194.87it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 536626.94it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1341678.73it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 797835.49it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1553210.16it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1736457.51it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 508965.16it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 951832.38it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 615079.44it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1054065.93it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Train the NN to get word embedings , Word Vectors\n",
    "for epoch in range(30):\n",
    "    model_ug_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dbow.alpha -= 0.001\n",
    "    model_ug_dbow.min_alpha = model_ug_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_vecs_dbow = get_vectors(model_ug_dbow, x_train, 100)\n",
    "validation_vecs_dbow = get_vectors(model_ug_dbow, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31459734,  0.05857672, -0.09373038,  0.20645429, -0.0509001 ,\n",
       "       -0.04946975, -0.31858325, -0.14537346, -0.66941994, -0.01894479,\n",
       "        0.25924209,  0.24269211, -0.04018043,  0.29951391,  0.14582373,\n",
       "        0.57815927,  0.06517559, -0.76638174,  0.10707678, -0.17196579,\n",
       "        0.77296329,  0.39612919,  0.44807401, -0.32401827,  0.34141243,\n",
       "       -0.40942451, -0.35081768,  0.58094424,  0.10882908,  0.0028272 ,\n",
       "       -0.046775  ,  0.15882301, -0.23425579, -0.24412428,  0.31141734,\n",
       "       -0.01923329, -0.11746588,  0.30261034, -0.14542373, -0.08741587,\n",
       "        0.80030155, -0.18588898,  0.28747362, -0.35675997,  0.31254163,\n",
       "        0.34251207,  0.6266402 , -0.52675885, -0.06801969,  0.03347588,\n",
       "        0.03746403,  0.19598594,  0.32230553,  0.1780279 , -0.11842416,\n",
       "        0.05042865, -0.28034997, -0.08156704,  0.1472228 , -0.23309168,\n",
       "       -0.33467588,  0.68091482, -0.24073295, -0.22109973, -0.11626986,\n",
       "       -0.02848517,  0.0330813 ,  0.11531822, -0.30272543, -0.42567974,\n",
       "       -0.03398323, -0.57538366,  0.23131865, -0.40902513, -0.08314061,\n",
       "        0.09840972,  0.26635253, -0.2834354 ,  0.12035388, -0.14161548,\n",
       "        0.13940643, -0.14671952,  0.06093591,  0.23122734,  0.02627293,\n",
       "        0.25331035,  0.05038817, -0.10968605,  0.07461189, -0.16417994,\n",
       "       -0.67051369,  0.07566323, -0.26717299, -0.05286108, -0.27931243,\n",
       "        0.02334328,  0.66650587, -0.1685781 ,  0.16433334, -0.09612427])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs_dbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08672442, -0.4462676 , -0.30447775,  0.21677081,  0.01122478,\n",
       "       -0.48521993, -0.2737031 , -0.4314875 , -0.3950983 ,  0.56958199,\n",
       "        0.24252385,  0.026979  , -0.18463492, -0.38044858,  0.08399496,\n",
       "        0.05719149,  0.23872964, -0.17824945,  0.08450142, -0.48350203,\n",
       "        0.34060234,  0.18874976,  0.00457577,  0.03561156,  0.4397355 ,\n",
       "       -0.50918812, -0.35386541,  0.08386976,  0.11599461, -0.2558915 ,\n",
       "       -0.12931962,  0.10156544, -0.34727541, -0.20918702,  0.28329754,\n",
       "       -0.00595026, -0.51317579,  0.37773061,  0.34114018, -0.26488337,\n",
       "        0.55541879, -0.32762384,  0.10969518, -0.22907384, -0.18569569,\n",
       "        0.15383907,  0.23259358, -0.32612538,  0.25151631,  0.10281659,\n",
       "        0.03070224, -0.19287577,  0.06740264, -0.03647917,  0.15792011,\n",
       "        0.01277175, -0.17274536, -0.03004599,  0.30016303, -0.53494048,\n",
       "       -0.10917096,  0.20187664, -0.37911767, -0.34020674, -0.19597563,\n",
       "        0.07272606, -0.33792499,  0.24224688,  0.25041366, -0.31506127,\n",
       "       -0.1552186 , -0.25736207,  0.26102847, -0.30389392, -0.14958186,\n",
       "       -0.11953028,  0.32170516, -0.00853839,  0.00309474,  0.00336486,\n",
       "       -0.09160712, -0.04037593, -0.14135323, -0.07617711,  0.01983964,\n",
       "        0.04144461, -0.0193229 , -0.21524695,  0.03026456, -0.46588483,\n",
       "       -0.12302542, -0.16140038,  0.03443121, -0.24126542, -0.3400245 ,\n",
       "        0.36300352,  0.51135355, -0.38823456,  0.1547472 , -0.05447906])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_vecs_dbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534246575342466"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ug_dbow.save('d2v_model_ug_dbow.doc2vec')\n",
    "model_ug_dbow = Doc2Vec.load('d2v_model_ug_dbow.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ug_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 468426.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#Distributed Memory\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmc.build_vocab([x for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14640/14640 [00:00<00:00, 922378.94it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 919933.04it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 737832.22it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 435030.89it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 922878.00it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 628006.69it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 984111.33it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 500167.88it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 868400.66it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 310692.33it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 819416.45it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1180177.02it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1644692.93it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 843330.91it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 894354.78it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 461123.66it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 868560.34it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1633622.71it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 952304.75it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 984347.97it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1017997.82it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 701069.91it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1018115.97it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 776831.05it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 756671.03it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 1341737.37it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 736010.39it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 738169.27it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 671139.98it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 14640/14640 [00:00<00:00, 468522.89it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmc.alpha -= 0.002\n",
    "    model_ug_dmc.min_alpha = model_ug_dmc.alpha"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "What's nice about Doc2Vec is that after training you can retrieve not only document vectors but also individual word vectors as well. Note, however, that a Doc2Vec DBOW model doesn't learn semantic word vectors, so the word vectors you retrieve from pure DBOW model will be the automatic randomly-initialized vectors, with no meaning. But with DM model, you can see the semantic relationship between words. Let's see what word vectors it has learned through training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gracious', 0.5554074048995972),\n",
       " ('inconsiderate', 0.5172461867332458),\n",
       " ('stories', 0.515602171421051),\n",
       " ('unpleasant', 0.5132873058319092),\n",
       " ('thin', 0.5083214044570923),\n",
       " ('disorganized', 0.5031203627586365),\n",
       " ('often', 0.4885654151439667),\n",
       " ('frustrated', 0.48758840560913086),\n",
       " ('likely', 0.46571025252342224),\n",
       " ('cycles', 0.4572683572769165)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_ug_dmc.most_similar('angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('impending', 0.4816121459007263),\n",
       " ('poor', 0.4799586534500122),\n",
       " ('extreme', 0.4722893238067627),\n",
       " ('makeup', 0.46474969387054443),\n",
       " ('lazy', 0.4473317265510559),\n",
       " ('blamed', 0.4359237849712372),\n",
       " ('beautiful', 0.4331815838813782),\n",
       " ('scollegelondon', 0.43048328161239624),\n",
       " ('simple', 0.42982858419418335),\n",
       " ('easy', 0.4262011647224426)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('evenlate', 0.7859842777252197),\n",
       " ('unloaded', 0.5288441777229309),\n",
       " ('prior', 0.4974138140678406),\n",
       " ('dark', 0.49580979347229004),\n",
       " ('comms', 0.45956066250801086),\n",
       " ('canx', 0.45501184463500977),\n",
       " ('ago', 0.45331692695617676),\n",
       " ('deadhead', 0.44632986187934875),\n",
       " ('hs', 0.4401280879974365),\n",
       " ('worstflight', 0.42932993173599243)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar('late')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96ank\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('understands', 0.45236513018608093),\n",
       " ('inside', 0.4419071078300476),\n",
       " ('compensating', 0.4377748668193817),\n",
       " ('vicky', 0.43512606620788574),\n",
       " ('snapchat', 0.42303600907325745),\n",
       " ('combined', 0.4224178194999695),\n",
       " ('issuing', 0.4216964542865753),\n",
       " ('placing', 0.4206436276435852),\n",
       " ('entering', 0.4195011258125305),\n",
       " ('opal', 0.4192591905593872)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar(positive=['bigger', 'small'], negative=['big'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
