{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'N7mHCm2vQ12lBsN0Q26aL6kNc'\n",
    "consumer_secret= 'Ahe5xcbLlrd9lvxmX0f4FDrwLXIbO5dkD1qHmFhca2uwnfaJu4'\n",
    "access_token= '122730495-dqvUECiBfdeNGCHrzznUlfUcZPqConYHvAkqhlYj'\n",
    "access_token_secret= 'DStgYNUUlkqUIW3cyxqqTTYu8S8EErmmXs6uH3C7x5ZER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post a tweet from Python\n",
    "#api.update_status(\"Look, I'm tweeting from #Python\")\n",
    "# Your tweet has been posted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search term and the date_since date as variables\n",
    "search_words = \"#wildfires\"\n",
    "date_since = \"2018-11-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.cursor.ItemIterator at 0x292e4c1e1c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since).items(5)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wildfires, which are made worse by climate change, have caused widespread destruction in Australia , Brazil , the U‚Ä¶ https://t.co/uY45rzxGEr\n",
      "RT @nswfire: New South Wales Fires - Australian Wildfires\n",
      "As seen from space \n",
      "\n",
      "25km north of Bairndale NSW Australia \n",
      "\n",
      "Src: @Pierre_Markuse‚Ä¶\n",
      "RT @Ruptly: State of emergency as #Valparaiso #wildfires rage on \n",
      "\n",
      "#Chile https://t.co/Hox4byMsFW\n",
      "RT @Ruptly: State of emergency as #Valparaiso #wildfires rage on \n",
      "\n",
      "#Chile https://t.co/Hox4byMsFW\n",
      "RT @Ruptly: State of emergency as #Valparaiso #wildfires rage on \n",
      "\n",
      "#Chile https://t.co/Hox4byMsFW\n"
     ]
    }
   ],
   "source": [
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IS it a same NDTV or is it being run by ISI now ? #NDTV https://t.co/QH0SxYF2Ya',\n",
       " '#FakeNewsMafia \\nBest Fake Channel - #NDTV, #bbcnews, #Indiatoday\\n\\nBest Fake news anchor - #Ravishkumar , #Rajdeep,‚Ä¶ https://t.co/erywoZ2e7O',\n",
       " 'Wherever #Congress goes, loyalty of #NDTV üêï follows. NDTV explaining benefits of #NPR in 2010.\\n@BJP4India‚Ä¶ https://t.co/OT11CwMZOu',\n",
       " 'On the 1 hand #Owaisi is shouting at the top of his voice that protesters included people from all Majhab not just‚Ä¶ https://t.co/WnB72wUDTY',\n",
       " 'No 1 is abusing EVM machine on Jharkhand result.  #ashutosh #NDTV #Zeenews #IndiaSupportsCAB #kanhaiyakumar #JNU']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_words = \"#ndtv\" + \" -filter:retweets\"\n",
    "date_since = \"2018-11-16\"\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since).items(5)\n",
    "\n",
    "# Collect a list of tweets\n",
    "[tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"‡§Æ‡•á‡§Ç ‡§á‡§Ç‡§ï‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Å  I REFUSE \" \\n#Inqalab #jindabad\\n#againstcaa #against #NRC_CAA_Protests #againstcab‚Ä¶ https://t.co/uFwj94xev1',\n",
       " '@htTweets Sir , Respected HM keh rahe hai \\nDelhi ki kacchi bastiyoo mei teen teen pedhi se gareeb rehta hai ,Aap ko‚Ä¶ https://t.co/OYKyTsaqoA',\n",
       " '‡§∏‡•ã‡§ö‡§§‡§æ  ‡§π‡•Ç‡§Å ‡§µ‡•ã ‡§ï‡§ø‡§§‡§®‡•á ‡§Æ‡§æ‡§∏‡•Ç‡§Æ ‡§•‡•á\\n‡§ï‡•ç‡§Ø‡§æ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã ‡§ó‡§è ‡§¶‡•á‡§ñ‡§§‡•á ‡§¶‡•á‡§ñ‡§§‡•á\\n\\n‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§∞‡§æ‡§ú ‡§Æ‡•á‡§Ç #NDTV ‡§ï‡•Ä ‡§è‡§®‡§∏‡•Ä‡§Ü‡§∞ ‡§™‡§∞ ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü‡§ø‡§Ç‡§ó ‡§¶‡•á‡§ñ‡§ø‡§è‚Ä¶ https://t.co/oSBDSMfpkG',\n",
       " '@DrKumarVishwas  ‡§ú‡•Ä  ‡§¶‡•á‡§ñ‡§ø‡§è  2010 ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§ß‡§ø ‡§ú‡•Ä #NDTV ‡§ï‡•à‡§∏‡•á  NPR  ‡§ï‡§æ  ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡•Ä ‡§•‡•Ä ‡•§ https://t.co/1w9FSxujQs',\n",
       " '#NDTV vs #GodiMedia . \\n\\n ‡§ï‡•ç‡§Ø‡§æ #BipinRawat ‡§ú‡•Ä ‡§∏‡•á‡§®‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§π‡•à ? \\n\\n #BVD26 #BrandedFakeer #BhartenduVimalDubey‚Ä¶ https://t.co/DxfOFJmelF']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get Hindi Tweets \n",
    "search_words = \"#ndtv\" + \" -filter:retweets\"\n",
    "date_since = \"2018-11-16\"\n",
    "# Collect tweets\n",
    "tweets_hindi = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"hi\",\n",
    "                       since=date_since).items(17000)\n",
    "\n",
    "# Collect a list of tweets\n",
    "#[tweet.text for tweet in tweets_hindi]\n",
    "tweets_hindi = [tweet.text for tweet in tweets_hindi]\n",
    "tweets_hindi[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe\n",
    "tweet_hindi_df = pd.DataFrame(data=tweets_hindi, \n",
    "                    columns=['text'])\n",
    "tweet_hindi_df.count()\n",
    "tweet_hindi_df.to_csv(r\"C:\\Users\\96ank\\Notebooks\\ndtv_hindi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sunilkapoor8', 'India'],\n",
       " ['AMBREESHKUMARA2', ''],\n",
       " ['rraushankhag', 'Mumbai, India'],\n",
       " ['IYRKRao', 'Andhra Pradesh, India'],\n",
       " ['tapasije', 'London, England']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tw.Cursor(api.search, \n",
    "                           q=search_words,\n",
    "                           lang=\"en\",\n",
    "                           since=date_since).items(5)\n",
    "\n",
    "users_locs = [[tweet.user.screen_name, tweet.user.location] for tweet in tweets]\n",
    "users_locs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sunilkapoor8</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AMBREESHKUMARA2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rraushankhag</td>\n",
       "      <td>Mumbai, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>IYRKRao</td>\n",
       "      <td>Andhra Pradesh, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tapasije</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user               location\n",
       "0     sunilkapoor8                  India\n",
       "1  AMBREESHKUMARA2                       \n",
       "2     rraushankhag          Mumbai, India\n",
       "3          IYRKRao  Andhra Pradesh, India\n",
       "4         tapasije        London, England"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Pandas Dataframe From A List of Tweet Data\n",
    "tweet_text = pd.DataFrame(data=users_locs, \n",
    "                    columns=['user', \"location\"])\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@ndtvindia By #NDTV in 2010\\n\\nhttps://t.co/SwZpZ7VX25',\n",
       " 'IS it a same NDTV or is it being run by ISI now ? #NDTV https://t.co/QH0SxYF2Ya',\n",
       " '#FakeNewsMafia \\nBest Fake Channel - #NDTV, #bbcnews, #Indiatoday\\n\\nBest Fake news anchor - #Ravishkumar , #Rajdeep,‚Ä¶ https://t.co/erywoZ2e7O',\n",
       " 'Wherever #Congress goes, loyalty of #NDTV üêï follows. NDTV explaining benefits of #NPR in 2010.\\n@BJP4India‚Ä¶ https://t.co/OT11CwMZOu',\n",
       " 'On the 1 hand #Owaisi is shouting at the top of his voice that protesters included people from all Majhab not just‚Ä¶ https://t.co/WnB72wUDTY']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_search = \"#NDTV -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=new_search,\n",
    "                   lang=\"en\",\n",
    "                   since='2019-09-01').items(10000)\n",
    "\n",
    "all_tweets = [tweet.text for tweet in tweets]\n",
    "all_tweets[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    806\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "tweet_pdf = pd.DataFrame(data=all_tweets, \n",
    "                    columns=['text'])\n",
    "tweet_pdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_pdf.to_csv(r\"C:\\Users\\96ank\\Notebooks\\ndtv1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
